<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Class Website</title>
    <link rel="stylesheet" href="style.css"> <!-- Optional: Add a CSS file for styling -->
</head>
<body>
    <header>
        <h1>CS 5955/6955 Advanced Artificial Intelligence</h1>
    </header>
    <nav>
        <ul>
            <li><a href="https://utah.instructure.com/courses/1027622/assignments/syllabus">Canvas Class Page</a></li>
            <li><a href="https://piazza.com/utah/spring2025/cs6955001spring2025/home">Piazza</a></li>
            <li><a href="#schedule">Schedule</a></li>
            <li><a href="#resources">Resources</a></li>
        </ul>
    </nav>


    <h2>Class Overview</h2>
    This course focuses on advanced algorithms for intelligent sequential decision making with a focus on modern deep learning-based methods. The class will cover both the theory and practical details of the algorithms behind recent breakthroughs in many types of AI decision making, including game playing, robotics, recommendation systems, and large language models. Topics include bandit algorithms, Markov decision processes, partially observable Markov decision processes, reinforcement learning, imitation learning, inverse reinforcement learning, and reinforcement learning from human feedback.

    This will be a fun, but challenging class.  It is an advanced AI class so we will assume a basic understanding of machine learning basics (supervised learning, loss functions, gradient descent) and a basic understanding of AI basics (search problems, MDPs, RL high-level ideas). Note that these topics can be picked up during the class as we will try to keep things self-contained, but we will go over basic topics quickly to get to more advanced materials. Students should be comfortable writing Python code and digging through and understanding code written by others.

    
    
    <section id="schedule">
        <h2>Class Schedule</h2>
        <table>
            <thead>
                <tr>
                    <th>Date</th>
                    <th>Topic</th>
                    <th>Slides</th>
                    <th>Readings</th>
                    <th>Assignment</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Jan 6</td>
                    <td>Class Intro</td>
                    <td><a href="slides/intro.pdf">Slides</a></td>
                    <td>Optional: <a href="readings/Python_Tips.pdf">Python Notes (Alan Kuntz)</a> </td>
                    <td>Optional: <a href="https://inst.eecs.berkeley.edu/~cs188/fa24/projects/proj0/">Python Tutorial (Berkeley AI Class)</a></td>
                </tr>
                 <tr>
                    <td>Jan 8</td>
                    <td>Behavioral Cloning</td>
                    <td><a href="slides/bc.pdf">Slides</a></td>
                    <td> Optional: <a href="https://arxiv.org/abs/1805.01954">Behavioral Cloning from Observation</a>, <a href="https://arxiv.org/abs/1011.0686">DAgger</a>, <a href="https://arxiv.org/abs/2109.08273">ThriftyDAgger</a> </td>
                    <td> <a href="https://github.com/dsbrown1331/imitation_learning">Behavior Cloning in PyTorch</a> (due Jan 15) </td>
                </tr>
                 <tr>
                    <td>Jan 13</td>
                    <td>Advanced Behavior Cloning</td>
                    <td></td>
                    <td>Choose one and submit reading report: <a href="https://arxiv.org/abs/2109.00137">Implicit Behavioral Cloning</a>, <a href="https://arxiv.org/abs/2304.13705">Action Chunking Transformer</a>, <a href="https://arxiv.org/abs/2303.04137">Diffusion Policy</a></td>
                    <td></td>
              
                </tr>
                <tr>
                    <td>Jan 15</td>
                    <td>Intro to Evaluative Feedback and Bandits</td>
                    <td></td>
                    <td></td>
                    <td></td>  
                </tr>
                <tr>
                    <td>Jan 22</td>
                    <td>More Bandits</td>
                    <td></td>
                    <td></td>
                    <td></td>  
                </tr>
                <tr>
                    <td>Jan 27</td>
                    <td>Markov Decision Processes</td>
                    <td></td>
                    <td></td>
                    <td></td>
                </tr>
                <tr>
                    <td>Jan 29</td>
                    <td>Reinforcement Learning Foundations</td>
                    <td></td>
                    <td></td>
                    <td></td>
                </tr>
                <tr>
                    <td>Feb 3</td>
                    <td>Value-Based RL</td>
                    <td></td>
                    <td></td>
                    <td></td>
                </tr>
                <tr>
                    <td>Feb 5</td>
                    <td>Policy-Based RL</td>
                    <td></td>
                    <td></td>
                    <td></td>
                </tr>
                <tr>
                    <td>Feb 10</td>
                    <td>AlphaGo and AlphaZero</td>
                    <td></td>
                    <td></td>
                    <td></td>
                </tr>
                <tr>
                    <td>Feb 12</td>
                    <td>Model-Based RL</td>
                    <td></td>
                    <td></td>
                    <td></td>
                </tr>
                <tr>
                    <td>Feb 19</td>
                    <td>Advance Deep RL</td>
                    <td></td>
                    <td></td>
                    <td></td>
                </tr>
                <tr>
                    <td>Feb 24</td>
                    <td>More Advanced Deep RL</td>
                    <td></td>
                    <td></td>
                    <td></td>
                </tr>
                <tr>
                    <td>Feb 26</td>
                    <td>Multi-Agent RL</td>
                    <td></td>
                    <td></td>
                    <td></td>
                </tr>
                <tr>
                    <td>Mar 3</td>
                    <td>RL from Human Feedback (RLHF)</td>
                    <td></td>
                    <td></td>
                    <td></td>
                </tr>
                <tr>
                    <td>Mar 5</td>
                    <td>More RL from Human Feedback (RLHF)</td>
                    <td></td>
                    <td></td>
                    <td></td>
                </tr>
            </tbody>
        </table>
    </section>
    <section id="resources">
        <h2>Additional Resources</h2>
        <p>Here you can find supplementary materials, links, etc.
        <ul>
            <li>Sutton and Barto RL books <a href="http://incompleteideas.net/book/ebook/the-book.html">First Edition (html)</a>, <a href="http://incompleteideas.net/book/RLbook2020.pdf">Second Edition (pdf)</a>
            <li><a href="https://ai.berkeley.edu/lecture_videos.html">Berkeley Intro AI Lectures (Scroll down to later years)</a> </li>
            <li>My Human-AI Alignment Class <a href="https://users.cs.utah.edu/~dsbrown/cs6960.html">Reading List</a></li>
            <li><a href="https://www.youtube.com/playlist?list=PLqYmG7hTraZDM-OYHWgPebj2MfCFzFObQ">David Silver RL Lectures</a></li>
        </ul>

        <p> PyTorch Tutorials</p>
        <ul>
            <li><a href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html">60 minute blitz</a></li>
            <li><a href="https://clemsonciti.github.io/rcde_workshops/pytorch/03-regression_and_classification.html">Regression and Classification</li>
            <li><a href="https://machinelearningmastery.com/building-a-regression-model-in-pytorch/">Regression</a></li>
            <li><a href="https://www.geeksforgeeks.org/classification-using-pytorch-linear-function/">Classification</a></li>
        </ul>

        
        </p>
    </section>

</body>
</html>
